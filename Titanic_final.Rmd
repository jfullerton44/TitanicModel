---
title: "Titanic Project"
author: "Jacob Fullerton, Levi Moneyhun, Yinhao Ge, and Amrita Singh"
date: "11/28/2018"
output: html_document
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This step libraries the necessary packages. 
```{r Libraries, message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(randomForest)
library(caret)
library(gmodels)
library(doSNOW)
registerDoSNOW(makeCluster(2, type = "SOCK"))
library(ada)
library(plyr)
library(dplyr)
library(ggplot2)
library(ipred)
library(adabag)
library(pROC)
library(randomForest)
```

This step imports the training and test data. It also ensures that several categorical variables are read as factors. 
```{r Initial Data Import}
titanic <- read.csv("titanic_train_set.csv", header = TRUE, sep = ",")
test <- read.csv("titanic_test_set.csv", header = TRUE, sep = ",")
titanic_test <- test
F=c(2,3,4,9)
for(i in F) titanic[,i]=as.factor(titanic[,i])
for(i in F) titanic_test[,i]=as.factor(test[,i])
```

The code below creates a new feature which represents standardized fare. Because fare depends on both class and departure location, standardizing fare by departure locations allows us to interpret the resulting feature as information about class more granularly than simply 1st, 2nd, and 3rd class. To create this feature, we calculated the mean fare for each location and divided individual observations by the mean for the corresponding location. 

```{r Standardize Fare by Departure Location}
l = length(titanic$Survived)
s_fare <- c()
q_fare <- c()
c_fare <- c()
obs = c(1:l)
for(i in obs)
{
    if(titanic[i,"Embarked"] == "S")
      {
        s_fare <- c(s_fare, titanic[i,"Fare"])
      }
    if(titanic[i,"Embarked"] == "Q")
      {
        q_fare <- c(q_fare, titanic[i,"Fare"])
      }
    if(titanic[i,"Embarked"] == "C")
      {
        c_fare <- c(c_fare, titanic[i,"Fare"])
      }
}
s_fare_mean <- mean(s_fare)
q_fare_mean <- mean(q_fare)
c_fare_mean <- mean(c_fare)
titanic$standardized_fare <- ifelse(titanic$Embarked == "S", titanic$Fare/s_fare_mean, 
                                    ifelse(titanic$Embarked == "Q", titanic$Fare/q_fare_mean, titanic$Fare/c_fare_mean))
titanic_test$standardized_fare <- ifelse(titanic_test$Embarked == "S", titanic_test$Fare/s_fare_mean, 
                                    ifelse(titanic_test$Embarked == "Q", 
                                           titanic_test$Fare/q_fare_mean, titanic_test$Fare/c_fare_mean))
```

This code creates an age range feature, which bins several significant cateories of ages. We used 16, 32, 48, and 64 as the cutoffs for these bins. Because the effect of age may not be strictly increasing or strictly decreasing (e.g., from 0-16, increases in age could result in a lower likelihood of survival, while, from 16-32, increases in age could result in a higher likelihood of survival). Capturing bins of age, as well as age as a continuous variable, allows algorithms to interpret age data in a more sophisticated manner. 
```{r Bin Age Range}
titanic$age_range <- as.factor(ifelse(titanic$Age < 16, 1, ifelse(titanic$Age < 32, 2, ifelse(titanic$Age < 48, 3, ifelse(titanic$Age < 64, 4, 5)))))
titanic_test$age_range <- as.factor(ifelse(titanic_test$Age < 16, 1, ifelse(titanic_test$Age < 32, 2, ifelse(titanic_test$Age < 48, 3, ifelse(titanic_test$Age < 64, 4, 5)))))
```

This code creates a new feature called group size based on ParCh (the number of parents and children which were on board with a given passenger) and SibSp (the number of siblings and spouses on board with a given passenger). 
```{r Gropusize}
titanic$groupsize <- titanic$Parch + titanic$SibSp
titanic_test$groupsize <- titanic_test$Parch + titanic_test$SibSp
```

We experimented with several other engineered features, which ultimately did not improve predictive success: 
1. age_sex: an eight-level categorical variable which encompassed all possible interactions of age_range and sex. 
2. groupsize_sex: a ten-level categorical variable which encompassed all possible interactions of groupsize and sex. 
3. likelymother: a two-level categorical variable which identified, on the basis of age, sex, and Parch, whether an individual was likely to be a mother.
4. alone: a two-level categorical variable which identified, on the basis of groupsize, whether an invidual was on-board by themselves. 

This code partitions the input data into training and validation sets, which will be used for hyperparameter tuning.
```{r Partition Data}
train_index <- createDataPartition(titanic$Survived,
                                   p = .75,
                                   list = FALSE,
                                   times = 1)
training_set <- titanic[train_index,]
training_set <- training_set[,-1]
titanic_test <- titanic_test[,-1]
validation_set <- titanic[-train_index,]
validation_set <- validation_set[,-1]
titanic <- titanic[,-1]
```

The code below was used for making random forest models. We ended up not using this as our final prediction model as we found boosting to be more accurate. We used a nested-loop structure to tune the hyperparameters nodesize and sampsize. The results of this tuning are below the code. 
```{r Make Model, echo=TRUE}
bestModel <- randomForest(training_set[,-1], training_set$Survived, 
                       sampsize = round(0.6*(length(training_set$Survived))),ntree = 500, 
                       mtry = sqrt(7), importance = TRUE)
print(bestModel)
predictions <- predict(bestModel, validation_set)
bestAccuracy <- mean(predictions == validation_set$Survived)
print("original Model")
print(bestAccuracy)
F=c(16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
N=c(5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,90,100,110,120,130,140,150,160,170,180,190,200)
Max = c(1,2,3,4,5,6)
for (j in F){
 for(i in N){
      titanic_model_new <- randomForest(training_set[,-1], training_set$Survived ,
                    nodesize = j,
                    sampsize = i,
                    ntree = 500, 
                    mtry = sqrt(7),
                    importance = TRUE)
      #Best current j = 12, best i = 45
      titanic_pred_new <- predict(titanic_model_new, validation_set)
    
     # CrossTable(validation_set$Survived, titanic_pred_new,
      #           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
        #         dnn = c('actual default', 'predicted default'))
      
      #print(postResample(titanic_pred_new, validation_set$Survived))
      accuracy <- mean(titanic_pred_new == validation_set$Survived)
      if( accuracy > bestAccuracy) {
        bestModel <- titanic_model_new
        bestAccuracy <- accuracy
        print(accuracy)
        besti <- i
        bestj <- j
        print("J")
        print(j)
        print("I")
        print(i)
      }
  }
}
rf_model <- bestModel
```
The best value for node size appears to be 12 and the best value for sample size appears to be 45.


The code below was used to find the best hyperparameters for the boosting model approach. This method uses a validation set approach where the various hyperparameters are tested over a single valiatation set.
```{r Boosted Params, eval=FALSE, message=TRUE, warning=TRUE, paged.print=TRUE}
Grid <- expand.grid(maxdepth=c(1,3,5,7,9,11),nu=c(.01,0.02,0.04,0.05,0.06),iter=c(120,130,140,150,160,170,180,190,200))
cv_opts = trainControl(method="cv", number=10)
set.seed(123)
#Grid <- expand.grid(maxdepth=c(2,3),nu=0.1,iter=c(50,100))
results_ada = train(Survived~., data=training_set, method="ada",
                    trControl=cv_opts,tuneGrid=Grid)
print(results_ada)
```


The code below creates the boosting model using the hyperparameters from above.
```{r Make boosted Model}
bestModel<-boosting(Survived ~ ., data=training_set, boos=FALSE, mfinal=120,maxdepth=9,nu=0.04)
```


The code below was used during random forests to determine the importance of each factor in prediction if a passenger survived. Note: this is based on the random forest model we developed, not the boosting model which we ended up using for our actual predictions. 
```{r Get Importance}
importance <- varImp(rf_model)
importance_sort <- importance[order(importance[,1], decreasing = TRUE),]
importance_sort
## Sex and Pclass are most important
```

This code creates a confusion matrix for the predicted outcomes on the validation set. 
```{r Validation}
validation_predict <- predict(bestModel, validation_set)
predictions <- as.factor(ifelse(validation_predict$class == "1", 1, 0))
confusionMatrix(data = predictions, reference = validation_set$Survived, mode = "prec_recall")
```

Here, we create the boosting model building on the entire titanic set for increased accuracy on the test set. 
```{r Make boosted Model Improved}
bestModel<-boosting(Survived ~ ., data=titanic, boos=FALSE, mfinal=120,maxdepth=9,nu=0.04)
```


Next, we create our final predictions and output them to a CSV file. 
```{r}
pred_vector <- predict(bestModel, titanic_test)
pred_table <- data.frame(ID=titanic_test$PassengerID, p=pred_vector$class)
pred_table
write.csv(pred_table, file="Prediction.csv", row.names = FALSE)
```

