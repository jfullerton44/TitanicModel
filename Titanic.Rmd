---
title: "Titanic Project"
author: "Jacob Fullerton, Levi Moneyhun, Yinhao Ge, and Amrita Singh"
date: "11/7/2018"
output: html_document
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(randomForest)
library(caret)
library(gmodels)
library(cvTools) 

titanic <- read.csv("titanic_train_set.csv", header = TRUE, sep = ",")
test <- read.csv("titanic_test_set.csv", header = TRUE, sep = ",")
F=c(2,3,4,9)
for(i in F) titanic[,i]=as.factor(titanic[,i])
for(i in F) test[,i]=as.factor(test[,i])
```

```{r Partition Data}
train_index <- createDataPartition(titanic$Survived,
                                   p = .75,
                                   list = FALSE,
                                   times = 1)

training_set <- titanic[train_index,]
training_set <- training_set[,-1]
validation_set <- titanic[-train_index,]
validation_set <- validation_set[,-1]
```

```{r Make Model}

bestModel <- randomForest(training_set[,-1], training_set$Survived, 
                       sampsize = round(0.6*(length(training_set$Survived))),ntree = 500, 
                       mtry = sqrt(7), importance = TRUE)
print(bestModel)
predictions <- predict(bestModel, validation_set)
bestAccuracy <- mean(predictions == validation_set$Survived)
print("original Model")
print(bestAccuracy)


F=c(16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
N=c(5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,90,100,110,120,130,140,150,160,170,180,190,200)
Max = c(1,2,3,4,5,6)


for (j in F){
 for(i in N){
      titanic_model_new <- randomForest(training_set[,-1], training_set$Survived ,
                    nodesize = j,
                    sampsize = i,
                    ntree = 500, 
                    mtry = sqrt(7),
                    importance = TRUE)
      #Best current j = 12, best i = 45
      titanic_pred_new <- predict(titanic_model_new, validation_set)
    
     # CrossTable(validation_set$Survived, titanic_pred_new,
      #           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
        #         dnn = c('actual default', 'predicted default'))
      
      #print(postResample(titanic_pred_new, validation_set$Survived))
      accuracy <- mean(titanic_pred_new == validation_set$Survived)
      if( accuracy > bestAccuracy) {
        bestModel <- titanic_model_new
        bestAccuracy <- accuracy
        print(accuracy)
        besti <- i
        bestj <- j
        print("J")
        print(j)
        print("I")
        print(i)
      }

  }
}

```
The best value for node size appears to be 12 and the best value for sample size appears to be 45.
```{r}
k <- 10 #the number of folds

dataset <- titanic

folds <- cvFolds(NROW(dataset), K=k)
dataset$holdoutpred <- rep(0,nrow(dataset))
accuracy.vector <- rep(0,k)
## Outer-Loop for Testing and Evaluation
for(i in 1:k){
  train <- dataset[folds$subsets[folds$which != i], ] #Set the training set
  test <- dataset[folds$subsets[folds$which == i], ] #Set the validation set
  ## Setup to run inner loop (indicate 5-fold CV):
  ControlParameters <- trainControl(method="cv", number = 5,
                                    savePredictions = TRUE,
                                    classProbs = FALSE)
  ## Running a random forest model; therefore, tune "mtry" values
  parameterGrid <-expand.grid(mtry=c(2,3,4,5))
  
  ## Inner-Loop for model selection:
  cvRandomModel <- train(Survived ~ ., data = train,
                         method = "rf",
                         trControl = ControlParameters,
                         tuneGrid = parameterGrid)
  ## End inner-loop
  ## Get prediction for ith test fold
  p <- predict(cvRandomModel,test)
  
  ## Check accuracy for the ith test fold
  
  accuracy.vector[i] <- mean(p==test$Survived)
  ## Save prediction values in the holdoutpred column you created in 
  ## the dataset
  dataset[folds$subsets[folds$which == i], ]$holdoutpred <- p
}
dataset$holdoutpred #do whatever you want with these predictions

crossAccuracy <- 1 - mean(dataset$holdoutpred == titanic$Survived)
print(crossAccuracy)
```

```{r}
rfcv(training_set[,-1], training_set$Survived )

```


```{r Get Importance}

importance <- varImp(bestModel)
importance_sort <- importance[order(importance[,1], decreasing = TRUE),]

importance_sort
## Sex and Pclass are most important, 

```


```{r Make Output}

print(test[,-2])
testOut <- predict(bestModel,test[,-1])



output <- transmute(test,
                  #  ID = PassengerID, 
                    p = testOut
)

write.csv(output,'submission.csv', quote= FALSE)              
```